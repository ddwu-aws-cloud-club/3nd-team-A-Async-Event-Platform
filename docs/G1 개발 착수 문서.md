# G1 — Analytics Pipeline & Metrics (Event Data + Athena)

## 1. Purpose

G1는 시스템이 “동작한다”를 넘어, **“얼마나 잘 동작하는지”를 수치로 증명**하는 단계다.  
G0에서 로그(Logs)로 확인하던 방식은 운영/분석에 한계가 있으므로, G1부터는 **정형 이벤트 데이터(Event Data)** 를 발행하고 **SQL(Athena)** 로 지표를 산출한다.

운영자는 아래 질문에 **즉시 SQL로 답할 수 있어야 한다**.

1. 특정 시간대 트래픽(유입량)은 몇 건인가?
2. 성공/거절/실패 비율은 어떻게 되는가?
3. p95 Queue Delay는 얼마인가?
4. p95 E2E Delay는 얼마인가?

---

## 2. Definitions (G1 Fixed)

본 문서에서 사용하는 시간/지표 정의는 G1에서 **고정**이며, PR 리뷰 기준으로 사용한다.

### 2.1 Time Anchors

- **Traffic(유입량)**: `queuedAt` (큐 정상 접수 시각)
- **Throughput(처리량)**: `finishedAt` (처리 완료 시각)
- **Delay Anchor**: 모든 지연 지표의 기준점은 `queuedAt`

> Partition(dt/hour)은 **ingestion time(적재 시각)** 기준으로 생성된다.  
> 지표 산출은 **event time(queuedAt/startedAt/finishedAt)** 기준으로 수행한다.

---

## 3. Architecture Overview

Worker(필수)와 Ingest(선택)가 **분석용 이벤트(JSON)** 를 발행하고, AWS 파이프라인으로 적재하여 Athena에서 분석한다.

### 3.1 Data Flow (Pipeline)

1. **Source**: Worker(필수), Ingest(선택) — 비즈니스 처리 후 이벤트 발행
2. **Router**: Amazon EventBridge — 이벤트 수집 및 라우팅
3. **Ingestion**: Amazon Kinesis Data Firehose — 버퍼링 후 S3 적재
4. **Storage**: Amazon S3 — 파티셔닝 경로로 적재 (NDJSON)
5. **Analytics**: Amazon Athena — 표준 SQL로 지표 산출

### 3.2 S3 Partitioning Rules (Ingestion Time)

- Prefix: `events/dt=YYYY-MM-DD/hour=HH/`
- 목적: Athena partition pruning을 통한 쿼리 성능 개선
- 파일 포맷: **NDJSON (1 line = 1 JSON event)**  
  Athena는 “한 레코드 = 한 이벤트”를 전제로 조회한다.

Firehose Prefix 예시:
- `events/dt=!{timestamp:yyyy-MM-dd}/hour=!{timestamp:HH}/`
- Error Prefix: `events/error/`

---

## 4. Event Model (G1 Fixed)

G1에서는 이벤트 타입을 과도하게 늘리지 않는다.  
**필수 이벤트는 1개(`ParticipationProcessed`)로 고정**한다.

### 4.1 Required Event

- Publisher(필수): **Worker**
- Event Type(고정): **`ParticipationProcessed`**
  - 성공/거절/실패 등 처리 완료 결과를 모두 포함

### 4.2 Optional Event

- `RequestFailed` (디버깅/원인 분석용)
  - failure 필드만으로 충분하면 생략 가능

---

## 5. Event Schema

### 5.1 EventBridge Envelope (AWS Fields)

```json
{
  "source": "kr.ac.dongduk.worker",
  "detail-type": "ParticipationProcessed",
  "detail": "{...JSON string...}"
}
```
- `detail`은 **string(JSON 직렬화 결과)** 이다.

### 5.2 Detail Payload (Project Schema — Fixed)

아래 필드는 G1에서 **필수**이며, 누락 시 PR Reject 기준으로 사용한다.

```json
{
"schemaVersion":1,
"env":"dev",
"eventId":"event-123",
"requestId":"req-abc-123",
"eventType":"FIRST_COME",
"finalStatus":"SUCCEEDED",
"resultCode":"SUCCESS",
"timestamps":{
"queuedAt":1704290000000,
"startedAt":1704290000100,
"finishedAt":1704290000250
},
"delivery":{
"attempt":1,
"isDlq":false
},
"failure":{
"failureClass":null,
"errorCode":null,
"errorMessage":null
},
"meta":{
"workerId":"local-1"
}
}

```

### Field Rules (Must)

- `timestamps.queuedAt`
    - Worker가 생성하는 값이 아니다.
    - **SQS 메시지/RequestItem에서 계승**되어야 한다.
- `finalStatus`
    - DB 최종 상태와 동일한 값으로 고정
        
        (`SUCCEEDED | REJECTED | FAILED_FINAL`)
        
- `delivery.isDlq`
    - DLQ 비율을 SQL로 산출하기 위한 필드
    - `true`는 **DLQ 큐에서 소비된 메시지** 또는 **DLQ redrive 이후 처리된 메시지**에만 설정
    - Main Queue 처리 건은 항상 `false`

---

## 6. Delay Model (G1 Fixed)

모든 분석의 기준점(Anchor)은 `queuedAt`이다.

`queuedAt`은 Ingest에서 **SQS enqueue 성공 직후( RECEIVED → QUEUED 전이 순간 )** 에만 기록한다.

| Metric | Formula | Meaning |
| --- | --- | --- |
| Queue Delay | `startedAt - queuedAt` | 큐에서 대기한 시간 |
| E2E Delay | `finishedAt - queuedAt` | 큐 정상 접수부터 최종 완료까지 총 시간 |

---

## 7. Implementation Requirements

### 7.1 Worker — Event Publishing (Required)

Worker는 처리 완료 후 `ParticipationProcessed` 이벤트를 발행한다.

### Publishing Failure Policy (Fixed)

EventBridge putEvents 실패는 **본 처리 결과를 변경하지 않는다**.

- `putEvents()` 실패 시 예외를 **전파하지 않는다** (swallow)
- DynamoDB 상태 전이 및 SQS ack 판단은 **기존 로직대로 진행**
- 최소 보장:
    - `log.warn` 1회
    - (선택) 실패 카운터 메트릭 1회
- 재시도/버퍼링은 G2 범위로 미룬다

### 7.2 Ingest — Query Regression Guard (Required)

`GET /me/participations?limit=20` 조회는 **GSI1 Query 방식 고정**을 유지해야 한다.

- Query: `GSI1PK = USER#{userId}`
- Order: `ScanIndexForward = false` (최신순)
- Scan 사용 금지
- “내 신청 내역”은 **QUEUED 이후 요청만 노출**
    - QUEUED 전이 시점에만 GSI1 키를 세팅한다는 G0 규칙 유지

### 7.3 Ingest — Event Publishing (Optional)

E2E 추적을 명확히 하려면 `ParticipationRequested` 이벤트를 발행할 수 있다.

- Timing: SQS enqueue 성공 직후
- Fields: `requestId`, `queuedAt`, `userId`

---

## 8. Infrastructure Setup (G1 Required)

G1 파이프라인은 아래 흐름을 만족해야 한다.

**EventBridge → Firehose → S3 → Athena**

### 8.1 S3 Bucket

- Example: `dongduk-event-datalake`
- Public access block: enabled

### 8.2 Firehose

- Destination: S3
- Prefix:
    - `events/dt=!{timestamp:yyyy-MM-dd}/hour=!{timestamp:HH}/`
- Error Prefix:
    - `events/error/`
- Buffer (test-friendly):
    - Interval: 60s
    - Size: 1MB

### 8.3 EventBridge Rule

- Name: `rule-worker-to-firehose`
- Pattern:

```json
{
"source":["kr.ac.dongduk.worker"],
"detail-type":["ParticipationProcessed","RequestFailed"]
}

```

- Target: Firehose stream

---

## 9. Athena Table Definition

### 9.1 External Table (DDL)

```sql
CREATEEXTERNALTABLE IFNOTEXISTS participation_logs (
  schemaVersionint,
  env string,
  eventId string,
  requestId string,
  eventType string,
  finalStatus string,
  resultCode string,
  timestamps struct<
    queuedAt:bigint,
    startedAt:bigint,
    finishedAt:bigint
>,
  delivery struct<
    attempt:int,
    isDlq:boolean
>,
  failure struct<
    failureClass: string,
    errorCode: string,
    errorMessage: string
>,
  meta struct<
    workerId: string
>
)
PARTITIONEDBY (dt string,hour string)
ROW FORMAT SERDE'org.openx.data.jsonserde.JsonSerDe'
WITH SERDEPROPERTIES (
'ignore.malformed.json'='true'
)
LOCATION's3://<YOUR_BUCKET>/events/'
TBLPROPERTIES (
'projection.enabled'='false'
);

```

### 9.2 Partition Load (G1: Manual Allowed)

```sql
MSCK REPAIRTABLE participation_logs;

```

> G2에서는 Glue/Projection 기반 자동화를 고려한다.
> 

---

## 10. Required Queries (G1 Evidence)

아래 쿼리는 실행 가능해야 하며, 결과 캡처를 산출물로 남긴다.

### 10.1 Traffic Volume (queuedAt)

```sql
SELECT
  dt,
hour,
  date_trunc('minute', from_unixtime(timestamps.queuedAt/1000))AS min_time,
count(*)AS traffic_per_min
FROM participation_logs
WHERE dt='2026-01-04'
GROUPBY1,2,3
ORDERBY min_timeDESC;

```

### 10.2 Throughput (finishedAt)

```sql
SELECT
  dt,
hour,
  date_trunc('minute', from_unixtime(timestamps.finishedAt/1000))AS min_time,
count(*)AS throughput_per_min
FROM participation_logs
WHERE dt='2026-01-04'
GROUPBY1,2,3
ORDERBY min_timeDESC;

```

### 10.3 Result Distribution (resultCode + isDlq)

```sql
SELECT
  resultCode,
  delivery.isDlq,
count(*)AS total_count,
  round(count(*)*100.0/sum(count(*))over(),2)AS ratio_percent
FROM participation_logs
WHERE dt='2026-01-04'
GROUPBY1,2
ORDERBY total_countDESC;

```

### 10.4 p95 Delay (Queue / E2E)

```sql
SELECT
  eventId,
  approx_percentile(CAST(timestamps.startedAt- timestamps.queuedAtASBIGINT),0.95)AS p95_queue_delay_ms,
  approx_percentile(CAST(timestamps.finishedAt- timestamps.queuedAtASBIGINT),0.95)AS p95_e2e_delay_ms
FROM participation_logs
WHERE dt='2026-01-04'
AND eventId='TARGET_EVENT'
GROUPBY eventId;

```

---

## 11. Data Validation (G1 Required)

### 11.1 Negative Delay Must Be 0

```sql
SELECT
count(*)AS negative_delay_count
FROM participation_logs
WHERE dt='2026-01-04'
AND (
    timestamps.finishedAt< timestamps.startedAt
OR timestamps.startedAt< timestamps.queuedAt
OR timestamps.finishedAt< timestamps.queuedAt
  );

```

### 11.2 Missing Timestamp Must Be 0

```sql
SELECT
count(*)AS missing_timestamp_count
FROM participation_logs
WHERE dt='2026-01-04'
AND (
    timestamps.queuedAtISNULL
OR timestamps.startedAtISNULL
OR timestamps.finishedAtISNULL
  );

```

---

## 12. Definition of Done (G1)

- [ ]  S3에 `events/dt=.../hour=.../` 구조로 이벤트 파일이 적재된다
- [ ]  Athena 테이블 생성 후 `MSCK REPAIR TABLE`로 파티션이 인식된다
- [ ]  아래 4개 지표를 SQL로 즉시 산출할 수 있다 (결과 캡처 포함)
    - [ ]  시간대별 요청량 (queuedAt)
    - [ ]  결과 분포 (resultCode + isDlq)
    - [ ]  p95 Queue Delay
    - [ ]  p95 E2E Delay
- [ ]  정합성 검증에서 음수 지연이 0건이다
- [ ]  EventBridge 발행 실패가 DynamoDB 상태 전이 및 SQS ack 판단에 영향이 없다 (swallow 정책)

---

## 13. PR Review Checklist (G1)

- [ ]  이벤트 payload에 `queuedAt/startedAt/finishedAt`이 모두 존재한다
- [ ]  `queuedAt`은 Worker 생성 값이 아니라 SQS/RequestItem에서 계승된 값이다
- [ ]  EventBridge 발행 실패가 본 처리(상태/ack)에 영향을 주지 않는다 (swallow)
- [ ]  Traffic=queuedAt, Throughput=finishedAt 기준으로 쿼리한다
- [ ]  `GET /me/participations`는 GSI1 Query + 최신순(ScanIndexForward=false)이며 Scan이 없다
- [ ]  음수 지연 검증 결과가 0이다
- [ ]  S3 prefix가 `events/dt=YYYY-MM-DD/hour=HH/`로 실제 생성된다
